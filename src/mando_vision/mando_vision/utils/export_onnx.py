#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# FILE: export_onnx.py
# AUTHOR: Geoffrey Hinton
# DESCRIPTION: PyTorch(.pt) ëª¨ë¸ì„ TensorRT ë³€í™˜ì— ìµœì í™”ëœ ONNX(.onnx) í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

from ultralytics import YOLO
import torch

def export_single_model(model_path, model_name):
    """ì§€ì •ëœ ë‹¨ì¼ ëª¨ë¸ì„ ONNX í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    print("â”€" * 50)
    print(f"ğŸš€ Starting export for: {model_name} ({model_path})")
    
    # 1. ë³€í™˜í•  .pt ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    try:
        model = YOLO(model_path)
        print(f"âœ… Model loaded successfully.")
    except Exception as e:
        print(f"âŒ ERROR: Failed to load model {model_path}. Reason: {e}")
        return

    # 2. ONNXë¡œ ëª¨ë¸ì„ ë³€í™˜(export)í•©ë‹ˆë‹¤.
    #    - half=True: FP16 ì •ë°€ë„ë¡œ ë³€í™˜í•˜ì—¬ RTX 40 ì‹œë¦¬ì¦ˆ GPU ì„±ëŠ¥ ê·¹ëŒ€í™”
    #    - dynamic=True: ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸° ì…ë ¥ì„ í—ˆìš© (TensorRT ë¹Œë“œ ì‹œ í•„ìˆ˜)
    #    - opset=12: ì•ˆì •ì ì¸ ONNX ë²„ì „ ì„¸íŠ¸ ì§€ì •
    try:
        output_name = model.export(
            format='onnx',
            half=True,
            dynamic=True,
            opset=12
        )
        print(f"âœ… SUCCESS: Model exported to ONNX format at: {output_name}")
    except Exception as e:
        print(f"âŒ ERROR: Failed to export {model_name}. Reason: {e}")
    print("â”€" * 50)

def main():
    # ë³€í™˜í•  ëª¨ë¸ ëª©ë¡ (íŒŒì¼ ê²½ë¡œì™€ ë³„ì¹­)
    models_to_export = {
        'traffic': './traffic.pt',
    }
    
    # PyTorch ë° CUDA í™˜ê²½ ì •ë³´ ì¶œë ¥
    print("PyTorch Version:", torch.__version__)
    print("CUDA available:", torch.cuda.is_available())
    if torch.cuda.is_available():
        print("CUDA Device Name:", torch.cuda.get_device_name(0))

    # ëª©ë¡ì— ìˆëŠ” ëª¨ë“  ëª¨ë¸ì„ ìˆœì°¨ì ìœ¼ë¡œ ë³€í™˜
    for name, path in models_to_export.items():
        export_single_model(path, name)

if __name__ == '__main__':
    main()